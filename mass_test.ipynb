{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "import pandas as pd \n",
    "from mass import Modify_Kernel as MKernel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_value = None\n",
    "data_stats = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "def run_test(data,missing_rate,mtype = \"mcar\",model = \"mass\",data_stats = None):\n",
    "    X = data[\"X\"]\n",
    "    Y = data[\"Y\"]\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "    train_X = make_missing(train_X,rate = missing_rate,type = mtype)\n",
    "    test_X = make_missing(test_X,rate = missing_rate,type = mtype)\n",
    "    \n",
    "    if model == \"mass\":\n",
    "        kernal = MKernel(None, data_stats)\n",
    "        kernal.set_nbins(param_value)\n",
    "\n",
    "\n",
    "        train_mod, test_mod = kernal.build_model(train_X, test_X)  # this does the pre-processing step\n",
    "\n",
    "        sim_train = kernal.transform(train_mod)\n",
    "        sim_test = kernal.transform(test_mod,train_mod)  # row = train, col = test\n",
    "\n",
    "        # Configure Kernel PCA for precomputed kernels\n",
    "        kpca = KernelPCA(kernel='precomputed')\n",
    "\n",
    "        # Transform data using Kernel PCA\n",
    "        X_kpca_train = kpca.fit_transform(sim_train)\n",
    "        X_kpca_test = kpca.transform(sim_test)\n",
    "\n",
    "    elif model == \"mean\":\n",
    "        # Mean imputation\n",
    "        imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "        # Fit the imputer on the training data and transform both training and test data\n",
    "        X_kpca_train = imputer.fit_transform(train_X)\n",
    "        X_kpca_test = imputer.transform(test_X)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #  Calculate F1 score and accuracy\n",
    "    # Initialize the RandomForest classifier\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    f1_scores = cross_val_score(rf, X_kpca_test, test_Y, cv=cv, scoring='f1_macro')\n",
    "    acc_scores = cross_val_score(rf, X_kpca_test, test_Y, cv=cv, scoring='accuracy')\n",
    "\n",
    "    # Print mean F1 score and accuracy\n",
    "    print(f\"Mean CV F1 Score {model}: {np.mean(f1_scores):.4f}\")\n",
    "    print(f\"Mean CV Accuracy {model}: {np.mean(acc_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone = pd.read_csv(\"data/abalone_test.csv\",header = None)\n",
    "abalone = {\"X\":np.array(abalone.iloc[:, :-1]),\n",
    "            \"Y\":np.array(abalone.iloc[:, -1])}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_missing(data, rate = 0.1, type = \"mcar\"):\n",
    "    missing_rate = rate  # 10% of the data will be missing\n",
    "    # Calculate the number of elements to set as missing\n",
    "    total_elements = data.size\n",
    "    missing_elements = int(total_elements * missing_rate)\n",
    "\n",
    "    # Create a random mask\n",
    "    #np.random.seed(1)\n",
    "\n",
    "    if type == \"mcar\":\n",
    "        mask_indices = np.random.choice(total_elements, missing_elements, replace=False)\n",
    "\n",
    "        # Convert flat indices to multi-dimensional indices\n",
    "        multi_indices = np.unravel_index(mask_indices, data.shape)\n",
    "\n",
    "        # Set selected elements to NaN\n",
    "        data[multi_indices] = np.nan\n",
    "    elif type == \"mnar\":\n",
    "        for col in range(data.shape[1]):\n",
    "            column_data = data[:, col]\n",
    "            median_value = np.percentile(column_data, 60)\n",
    "            #print(len(upper_quantile_indices))\n",
    "            upper_quantile_indices = np.where(column_data > median_value)[0]\n",
    "            missingnum = int(missing_elements/data.shape[1])\n",
    "\n",
    "            selected_indices = np.random.choice(upper_quantile_indices,missingnum , replace=False)\n",
    "            data[selected_indices, col] = np.nan\n",
    "\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stats = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syn 1 (Simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'syn_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m## M0 \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m run_test(syn_1,\u001b[39m0.05\u001b[39m)\n\u001b[1;32m      3\u001b[0m run_test(syn_1,\u001b[39m0.2\u001b[39m)\n\u001b[1;32m      4\u001b[0m run_test(syn_1,\u001b[39m0.5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'syn_1' is not defined"
     ]
    }
   ],
   "source": [
    "## M0 \n",
    "run_test(syn_1,0.05)\n",
    "run_test(syn_1,0.2)\n",
    "run_test(syn_1,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modify\n",
    "run_test(syn_1,0.05)\n",
    "run_test(syn_1,0.2)\n",
    "run_test(syn_1,0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNAR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Banknote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "run_test(banknote,0.05,\"mnar\")\n",
    "run_test(syn_1,0.05,\"mnar\",\"mean\")\n",
    "\n",
    "\n",
    "# run_test(banknote,0.1,\"mnar\")\n",
    "# run_test(banknote,0.1,\"mnar\",\"mean\")\n",
    "\n",
    "\n",
    "# run_test(banknote,0.3,\"mnar\")\n",
    "# run_test(banknote,0.3,\"mnar\",\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
