{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "import pandas as pd \n",
    "from mass import Modify_Kernel as MKernel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_value = None\n",
    "data_stats = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone = pd.read_csv(\"data/abalone_test.csv\",header = None)\n",
    "abalone = {\"X\":np.array(abalone.iloc[:, :-1]),\n",
    "            \"Y\":np.array(abalone.iloc[:, -1])}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_missing(data, rate = 0.1, type = \"mcar\"):\n",
    "    missing_rate = rate  # 10% of the data will be missing\n",
    "    # Calculate the number of elements to set as missing\n",
    "    total_elements = data.size\n",
    "    missing_elements = int(total_elements * missing_rate)\n",
    "\n",
    "    # Create a random mask\n",
    "    #np.random.seed(1)\n",
    "\n",
    "    if type == \"mcar\":\n",
    "        mask_indices = np.random.choice(total_elements, missing_elements, replace=False)\n",
    "\n",
    "        # Convert flat indices to multi-dimensional indices\n",
    "        multi_indices = np.unravel_index(mask_indices, data.shape)\n",
    "\n",
    "        # Set selected elements to NaN\n",
    "        data[multi_indices] = np.nan\n",
    "    elif type == \"mnar\":\n",
    "        for col in range(data.shape[1]):\n",
    "            column_data = data[:, col]\n",
    "            median_value = np.percentile(column_data, 60)\n",
    "            #print(len(upper_quantile_indices))\n",
    "            upper_quantile_indices = np.where(column_data > median_value)[0]\n",
    "            missingnum = int(missing_elements/data.shape[1])\n",
    "\n",
    "            selected_indices = np.random.choice(upper_quantile_indices,missingnum , replace=False)\n",
    "            data[selected_indices, col] = np.nan\n",
    "\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stats = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syn 1 (Simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'syn_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m## M0 \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m run_test(syn_1,\u001b[39m0.05\u001b[39m)\n\u001b[1;32m      3\u001b[0m run_test(syn_1,\u001b[39m0.2\u001b[39m)\n\u001b[1;32m      4\u001b[0m run_test(syn_1,\u001b[39m0.5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'syn_1' is not defined"
     ]
    }
   ],
   "source": [
    "## M0 \n",
    "run_test(syn_1,0.05)\n",
    "run_test(syn_1,0.2)\n",
    "run_test(syn_1,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modify\n",
    "run_test(syn_1,0.05)\n",
    "run_test(syn_1,0.2)\n",
    "run_test(syn_1,0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNAR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Banknote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "run_test(banknote,0.05,\"mnar\")\n",
    "run_test(syn_1,0.05,\"mnar\",\"mean\")\n",
    "\n",
    "\n",
    "# run_test(banknote,0.1,\"mnar\")\n",
    "# run_test(banknote,0.1,\"mnar\",\"mean\")\n",
    "\n",
    "\n",
    "# run_test(banknote,0.3,\"mnar\")\n",
    "# run_test(banknote,0.3,\"mnar\",\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### abalone - Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m## Modify\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m run_test_reg(abalone,\u001b[39m0.05\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mmnar\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m \u001b[39m# run_test_reg(abalone,0.1,\"mnar\")\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# run_test_reg(abalone,0.3,\"mnar\")\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 15\u001b[0m, in \u001b[0;36mrun_test_reg\u001b[0;34m(data, missing_rate, data_stats, mtype)\u001b[0m\n\u001b[1;32m     11\u001b[0m kernal \u001b[39m=\u001b[39m MKernel(\u001b[39mNone\u001b[39;00m, data_stats)\n\u001b[1;32m     12\u001b[0m kernal\u001b[39m.\u001b[39mset_nbins(param_value)\n\u001b[0;32m---> 15\u001b[0m train_mod, test_mod \u001b[39m=\u001b[39m kernal\u001b[39m.\u001b[39;49mbuild_model(train_X, test_X)  \u001b[39m# this does the pre-processing step\u001b[39;00m\n\u001b[1;32m     17\u001b[0m sim_train \u001b[39m=\u001b[39m kernal\u001b[39m.\u001b[39mtransform(train_mod)\n\u001b[1;32m     18\u001b[0m sim_test \u001b[39m=\u001b[39m kernal\u001b[39m.\u001b[39mtransform(test_mod,train_mod)  \u001b[39m# row = train, col = test\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/pattern/rep/mass_incomplete/mass.py:82\u001b[0m, in \u001b[0;36mModify_Kernel.build_model\u001b[0;34m(self, train, test)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnbins_ \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(np\u001b[39m.\u001b[39mlog2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndata_) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m     81\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdimVec_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim_)])\n\u001b[0;32m---> 82\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdiscretiser_ \u001b[39m=\u001b[39m EqualFrequencyDiscretizer(train, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnbins_, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstats_)\n\u001b[1;32m     83\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbin_cuts_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbin_counts_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdiscretiser_\u001b[39m.\u001b[39mget_bin_cuts_counts()\n\u001b[1;32m     84\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_bins_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdiscretiser_\u001b[39m.\u001b[39mget_num_bins()\n",
      "File \u001b[0;32m~/Desktop/pattern/rep/mass_incomplete/mass.py:177\u001b[0m, in \u001b[0;36mEqualFrequencyDiscretizer.__init__\u001b[0;34m(self, data, nbins, stats)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_bins \u001b[39m=\u001b[39m [\u001b[39m0\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dim)]\n\u001b[1;32m    176\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dim):\n\u001b[0;32m--> 177\u001b[0m   \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstats \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mor\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mNumeric\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstats[\u001b[39m\"\u001b[39;49m\u001b[39mattribute\u001b[39;49m\u001b[39m\"\u001b[39;49m][i][\u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m]):\n\u001b[1;32m    178\u001b[0m     column_data \u001b[39m=\u001b[39m data[:, i] \u001b[39m# looking at each column\u001b[39;00m\n\u001b[1;32m    179\u001b[0m     \u001b[39m# Filter out NaN values from the column\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "## Modify\n",
    "run_test_reg(abalone,0.05,\"mnar\")\n",
    "# run_test_reg(abalone,0.1,\"mnar\")\n",
    "# run_test_reg(abalone,0.3,\"mnar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "def run_test(data,missing_rate,mtype = \"mcar\",model = \"mass\",data_stats = None):\n",
    "    X = data[\"X\"]\n",
    "    Y = data[\"Y\"]\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "    train_X = make_missing(train_X,rate = missing_rate,type = mtype)\n",
    "    test_X = make_missing(test_X,rate = missing_rate,type = mtype)\n",
    "    \n",
    "    if model == \"mass\":\n",
    "        kernal = MKernel(None, data_stats)\n",
    "        kernal.set_nbins(param_value)\n",
    "\n",
    "\n",
    "        train_mod, test_mod = kernal.build_model(train_X, test_X)  # this does the pre-processing step\n",
    "\n",
    "        sim_train = kernal.transform(train_mod)\n",
    "        sim_test = kernal.transform(test_mod,train_mod)  # row = train, col = test\n",
    "\n",
    "        # Configure Kernel PCA for precomputed kernels\n",
    "        kpca = KernelPCA(kernel='precomputed')\n",
    "\n",
    "        # Transform data using Kernel PCA\n",
    "        X_kpca_train = kpca.fit_transform(sim_train)\n",
    "        X_kpca_test = kpca.transform(sim_test)\n",
    "\n",
    "    elif model == \"mean\":\n",
    "        # Mean imputation\n",
    "        imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "        # Fit the imputer on the training data and transform both training and test data\n",
    "        X_kpca_train = imputer.fit_transform(train_X)\n",
    "        X_kpca_test = imputer.transform(test_X)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #  Calculate F1 score and accuracy\n",
    "    # Initialize the RandomForest classifier\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    f1_scores = cross_val_score(rf, X_kpca_test, test_Y, cv=cv, scoring='f1_macro')\n",
    "    acc_scores = cross_val_score(rf, X_kpca_test, test_Y, cv=cv, scoring='accuracy')\n",
    "\n",
    "    # Print mean F1 score and accuracy\n",
    "    print(f\"Mean CV F1 Score {model}: {np.mean(f1_scores):.4f}\")\n",
    "    print(f\"Mean CV Accuracy {model}: {np.mean(acc_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_test_reg(data,missing_rate,data_stats,mtype = \"mcar\"):\n",
    "    X = data[\"X\"]\n",
    "    Y = data[\"Y\"]\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "    train_X = make_missing(train_X,rate = missing_rate,type = mtype)\n",
    "    test_X = make_missing(test_X,rate = missing_rate,type = mtype)\n",
    "    # modify_krn = Modify_Kernel(None, data_stats)\n",
    "    # modify_krn.set_nbins(param_value)\n",
    "    kernal = MKernel(None, data_stats)\n",
    "    kernal.set_nbins(param_value)\n",
    "\n",
    "\n",
    "    train_mod, test_mod = kernal.build_model(train_X, test_X)  # this does the pre-processing step\n",
    "\n",
    "    sim_train = kernal.transform(train_mod)\n",
    "    sim_test = kernal.transform(test_mod,train_mod)  # row = train, col = test\n",
    "\n",
    "\n",
    "    # Configure Kernel PCA for precomputed kernels\n",
    "    kpca = KernelPCA(kernel='precomputed')\n",
    "\n",
    "    # Transform data using Kernel PCA\n",
    "    X_kpca_train = kpca.fit_transform(sim_train)\n",
    "    X_kpca_test = kpca.transform(sim_test)\n",
    "\n",
    "    # Initialize the RandomForest regressor\n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    mse_scores = cross_val_score(rf, X_kpca_test, test_Y, cv=cv, scoring='neg_mean_squared_error')\n",
    "    mae_scores = cross_val_score(rf, X_kpca_test, test_Y, cv=cv, scoring='neg_mean_absolute_error')\n",
    "\n",
    "    # Print mean MSE and MAE\n",
    "    print(f\"Mean Cross-Validation MSE: {-np.mean(mse_scores):.4f}\")\n",
    "    print(f\"Mean Cross-Validation MAE: {-np.mean(mae_scores):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
