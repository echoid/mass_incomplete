{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_missing_rates(data):    \n",
    "    # Calculate the overall missing rate\n",
    "    total_missing = np.isnan(data).sum()\n",
    "    total_elements = data.size\n",
    "    overall_missing_rate = total_missing / total_elements\n",
    "    print(f\"Overall missing rate: {overall_missing_rate:.2%}\")\n",
    "    \n",
    "    # # Calculate the missing rate for each column\n",
    "    # column_missing_rates = {}\n",
    "    # for i in range(data.shape[1]):\n",
    "    #     column_missing_rate = np.isnan(data[:, i]).mean()\n",
    "    #     column_missing_rates[f'feature_{i}'] = column_missing_rate\n",
    "    #     print(f\"Missing rate for column 'feature_{i}': {column_missing_rate:.2%}\")\n",
    "    \n",
    "    # return {\"overall\": overall_missing_rate, \"columns\": column_missing_rates}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "namelist = [\"car\",\"breast\",\n",
    "            \"australian\",\"heart\",\"adult\",\"student\",\n",
    "            \"banknote\",\"sonar\",\"spam\",\"wine\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "namelist = [\n",
    "            \"adult\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCAR\n",
    "\n",
    "Missing rate : 5，10，20，30，40，50，60，70，80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_rate = [0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def make_mcar(data, missing_rate=0.1, seed=1):\n",
    "    # Convert the data to float if it's not already, so it can hold NaN values\n",
    "    data = data.astype(float)\n",
    "    \n",
    "    total_elements = data.size\n",
    "    missing_elements = int(total_elements * missing_rate)\n",
    "\n",
    "    # Create a copy of the data to avoid modifying the original array\n",
    "    data_with_missing = data.copy()\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    mask_indices = np.random.choice(total_elements, missing_elements, replace=False)\n",
    "\n",
    "    # Convert flat indices to multi-dimensional indices\n",
    "    multi_indices = np.unravel_index(mask_indices, data.shape)\n",
    "\n",
    "    # Set selected elements to NaN\n",
    "    data_with_missing[multi_indices] = np.nan\n",
    "\n",
    "    return data_with_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataname in namelist:\n",
    "    data = np.array(pd.read_csv(f\"dataset/{dataname}/features.csv\"))\n",
    "    for rate in missing_rate:\n",
    "        missingdata = make_mcar(data, missing_rate=rate, seed=1)\n",
    "\n",
    "        #print(f\"Missing rate analysis for dataset: {dataname}\")\n",
    "        #missing_rates = calculate_missing_rates(missingdata)\n",
    "        \n",
    "            # Create the directory if it doesn't exist\n",
    "        output_dir = f\"dataset_nan/{dataname}/mcar\"\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "    # Save the data with missing values as a NumPy array\n",
    "        np.save(f\"{output_dir}/{rate}.npy\", missingdata)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAR\n",
    "\n",
    "BREAST Heart, Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#namelist = [\"breast\",\"heart\",\"adult\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing rate analysis for dataset: adult\n",
      "Missing rate analysis for dataset: adult\n",
      "Missing rate analysis for dataset: adult\n",
      "Missing rate analysis for dataset: adult\n",
      "Missing rate analysis for dataset: adult\n",
      "Missing rate analysis for dataset: adult\n",
      "Missing rate analysis for dataset: adult\n",
      "Missing rate analysis for dataset: adult\n",
      "Missing rate analysis for dataset: adult\n"
     ]
    }
   ],
   "source": [
    "for dataname in namelist:\n",
    "    data = np.array(pd.read_csv(f\"dataset/{dataname}/features.csv\"))\n",
    "    for rate in missing_rate:\n",
    "        missingdata = make_mar(data, p=rate, p_obs= 0.2)\n",
    "\n",
    "        print(f\"Missing rate analysis for dataset: {dataname}\")\n",
    "        #missing_rates = calculate_missing_rates(missingdata)\n",
    "        output_dir = f\"dataset_nan/{dataname}/mar\"\n",
    "        if not os.path.exists(output_dir):\n",
    "           os.makedirs(output_dir)\n",
    "\n",
    "    #Save the data with missing values as a NumPy array\n",
    "        np.save(f\"{output_dir}/{rate}.npy\", missingdata)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy import optimize\n",
    "\n",
    "def fit_intercepts(X, coeffs, p, self_mask=False):\n",
    "    if self_mask:\n",
    "        d = len(coeffs)\n",
    "        intercepts = torch.zeros(d)\n",
    "        for j in range(d):\n",
    "            def f(x):\n",
    "                return torch.sigmoid(X * coeffs[j] + x).mean().item() - p\n",
    "            intercepts[j] = optimize.bisect(f, -50, 50)\n",
    "    else:\n",
    "        d_obs, d_na = coeffs.shape\n",
    "        intercepts = torch.zeros(d_na)\n",
    "        \n",
    "        # Ensure X and coeffs are in floating-point format\n",
    "        X = X.float()\n",
    "        coeffs = coeffs.float()\n",
    "\n",
    "        for j in range(d_na):\n",
    "            def f(x):\n",
    "                return torch.sigmoid(X.mv(coeffs[:, j]) + x).mean().item() - p\n",
    "            \n",
    "            intercepts[j] = optimize.bisect(f, -50, 50)\n",
    "    \n",
    "    return intercepts\n",
    "\n",
    "def pick_coeffs(X, idxs_obs=None, idxs_nas=None, self_mask=False):\n",
    "    n, d = X.shape\n",
    "    if self_mask:\n",
    "        coeffs = torch.randn(d).float()  # Ensure coeffs are float\n",
    "        Wx = X * coeffs\n",
    "        coeffs /= torch.std(Wx, 0)\n",
    "    else:\n",
    "        d_obs = len(idxs_obs)\n",
    "        d_na = len(idxs_nas)\n",
    "        coeffs = torch.randn(d_obs, d_na).float()  # Ensure coeffs are float\n",
    "\n",
    "        # Convert indices to LongTensor for PyTorch operations\n",
    "        idxs_obs = torch.tensor(idxs_obs, dtype=torch.long)\n",
    "        idxs_nas = torch.tensor(idxs_nas, dtype=torch.long)\n",
    "\n",
    "        # Ensure the data is in floating-point format\n",
    "        X = X.float()  # Ensure X is a floating-point tensor\n",
    "\n",
    "        # Perform operations\n",
    "        Wx = X[:, idxs_obs].mm(coeffs)\n",
    "        coeffs /= torch.std(Wx, 0, keepdim=True)\n",
    "    return coeffs\n",
    "\n",
    "def make_mar(X, p, p_obs):\n",
    "    n, d = X.shape\n",
    "\n",
    "    to_torch = torch.is_tensor(X)  # Determine if X is a PyTorch tensor or a NumPy array\n",
    "    if not to_torch:\n",
    "        X = torch.from_numpy(X)\n",
    "\n",
    "    # Initialize a boolean mask\n",
    "    mask = torch.zeros(n, d).bool()\n",
    "\n",
    "    # Calculate the number of observed variables and the number of potentially missing variables\n",
    "    d_obs = max(int(p_obs * d), 1)\n",
    "    d_na = d - d_obs\n",
    "\n",
    "    # Select indices for observed and potentially missing variables\n",
    "    idxs_obs = np.random.choice(d, d_obs, replace=False)\n",
    "    idxs_nas = np.array([i for i in range(d) if i not in idxs_obs])\n",
    "\n",
    "    # Generate coefficients and intercepts for the logistic model\n",
    "    coeffs = pick_coeffs(X, idxs_obs, idxs_nas)\n",
    "    intercepts = fit_intercepts(X[:, idxs_obs], coeffs, p)\n",
    "\n",
    "    # Ensure X, coeffs, and intercepts are floating-point tensors\n",
    "    X = X.float()\n",
    "    coeffs = coeffs.float()\n",
    "    intercepts = intercepts.float()\n",
    "\n",
    "    # Calculate the probabilities using the logistic model\n",
    "    ps = torch.sigmoid(X[:, idxs_obs].mm(coeffs) + intercepts)\n",
    "\n",
    "    # Generate random values and apply the mask\n",
    "    ber = torch.rand(n, d_na)\n",
    "    mask[:, idxs_nas] = ber < ps\n",
    "\n",
    "    # Apply the mask to X, setting the masked elements to NaN\n",
    "    X[mask] = float('nan')\n",
    "\n",
    "    # Convert back to numpy array if the input was a numpy array\n",
    "    if not to_torch:\n",
    "        X = X.numpy()\n",
    "\n",
    "    return X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# namelist = [#\"car\",\"breast\",\n",
    "#             #\"australian\",\"heart\",\"adult\",\"student\",\n",
    "#             \"banknote\",\"sonar\",\"spam\",\"wine\"\n",
    "#             ]\n",
    "\n",
    "def make_mnar(X, percentile):\n",
    "    # Copy the array to avoid altering the original one\n",
    "    X_mnar = X.copy()\n",
    "    percentile = percentile * 100\n",
    "    # Iterate over each column in the array\n",
    "    for col in range(X_mnar.shape[1]):\n",
    "        # Calculate the percentile value for the current column\n",
    "        threshold = np.percentile(X_mnar[:, col], percentile)\n",
    "\n",
    "        # Replace values less than the threshold with np.nan\n",
    "        X_mnar[:, col] = np.where(X_mnar[:, col] < threshold, np.nan, X_mnar[:, col])\n",
    "\n",
    "    return X_mnar\n",
    "\n",
    "# Example usage\n",
    "# Assuming `data` is your NumPy array and `percentile` is your threshold:\n",
    "# missingdata = make_mnar(data, percentile=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mnar_columnwise(data, col_info, percentile):\n",
    "    data_mnar = data.copy()\n",
    "    percentile = percentile*100\n",
    "    for col, col_type in col_info.items():\n",
    "        col_idx = int(col)  # Assuming the keys in `col_info` correspond to column indices\n",
    "\n",
    "        if \"numerical\" in col_type:\n",
    "            # Calculate the percentile value for the numerical column\n",
    "            threshold = np.percentile(data_mnar[:, col_idx], percentile)\n",
    "            # Replace values less than the threshold with np.nan\n",
    "            data_mnar[:, col_idx] = np.where(data_mnar[:, col_idx] < threshold, np.nan, data_mnar[:, col_idx])\n",
    "\n",
    "        elif \"ordinal\" in col_type:\n",
    "            # Use the ordinal mapping from JSON to process the column\n",
    "            ordinal_map = col_type['ordinal']\n",
    "            threshold = np.percentile([ordinal_map.get(val, np.nan) for val in data_mnar[:, col_idx]], percentile)\n",
    "            # Replace values less than the threshold with np.nan\n",
    "            data_mnar[:, col_idx] = np.where([ordinal_map.get(val, np.nan) < threshold for val in data_mnar[:, col_idx]], np.nan, data_mnar[:, col_idx])\n",
    "\n",
    "        elif \"nominal\" in col_type:\n",
    "            # Nominal data typically isn't ordinal or numerical, but let's apply a similar logic\n",
    "            # Convert nominal categories to numbers using some encoding (this is an assumption)\n",
    "            unique_vals = list(set(data_mnar[:, col_idx]))\n",
    "            mapping = {val: i for i, val in enumerate(unique_vals)}\n",
    "            # Calculate the percentile value for the nominal column (based on its encoded values)\n",
    "            threshold = np.percentile([mapping.get(val, np.nan) for val in data_mnar[:, col_idx]], percentile)\n",
    "            # Replace values less than the threshold with np.nan\n",
    "            data_mnar[:, col_idx] = np.where([mapping.get(val, np.nan) < threshold for val in data_mnar[:, col_idx]], np.nan, data_mnar[:, col_idx])\n",
    "\n",
    "    return data_mnar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "\n",
    "# namelist = [#\"car\",\"breast\",\n",
    "#             \"australian\",\n",
    "#             #\"heart\",\"adult\",\"student\",\n",
    "#             #\"banknote\",\"sonar\",\"spam\",\"wine\"\n",
    "#             ]\n",
    "namelist = [#\"car\",\n",
    "    \"adult\",\n",
    "            #\"australian\",\n",
    "            #\"heart\",\"adult\",\"student\",\n",
    "            #\"banknote\",\"sonar\",\"spam\",\"wine\"\n",
    "            ]\n",
    "def make_mnar_columnwise(data, col_info, q, random_seed=1):\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "    q = q * 100\n",
    "    data_mnar = data.astype(float)\n",
    "\n",
    "    missing_rates = {}\n",
    "\n",
    "    for col, col_type in col_info.items():\n",
    "        col_idx = int(col)  # Assuming the keys in `col_info` correspond to column indices\n",
    "        num_to_remove = int(len(data_mnar) * q / 100)\n",
    "        if \"numerical\" in col_type:\n",
    "            # Calculate the percentile value for the numerical column\n",
    "            threshold = np.percentile(data_mnar[:, col_idx], q)\n",
    "            # Replace values less than the threshold with np.nan\n",
    "            data_mnar[:, col_idx] = np.where(data_mnar[:, col_idx] < threshold, np.nan, data_mnar[:, col_idx])\n",
    "\n",
    "            # Calculate the missing rate for this column\n",
    "            missing_rate = np.mean(np.isnan(data_mnar[:, col_idx])) * 100\n",
    "            missing_rates[col_idx] = missing_rate\n",
    "            #print(\"numerical\" ,missing_rate)\n",
    "\n",
    "        elif \"ordinal\" in col_type:\n",
    "            # Use the ordinal mapping from JSON to find the top two largest ordinal values\n",
    "            ordinal_map = col_type['ordinal']\n",
    "            max_value = max(ordinal_map.values())\n",
    "\n",
    "            # Find the indices where the values in the column are greater than or equal to max_value - 1\n",
    "            max_indices = np.where(data_mnar[:, col_idx] >= (max_value - 2))[0].tolist()\n",
    "\n",
    "            # Find the rest of the indices (those not in max_indices)\n",
    "            all_indices = set(range(data_mnar.shape[0]))\n",
    "            other_indices = list(all_indices - set(max_indices))\n",
    "\n",
    "            # Determine which indices to remove based on the number to remove\n",
    "            if len(max_indices) >= num_to_remove:\n",
    "                remove_indices = random.sample(max_indices, num_to_remove)\n",
    "            else:\n",
    "                # If there are not enough max_indices, take all max_indices and supplement with random others\n",
    "                remove_indices = max_indices\n",
    "                random_indices = random.sample(other_indices, num_to_remove - len(remove_indices))\n",
    "                #remove_indices = remove_indices + random_indices\n",
    "\n",
    "            data_mnar[remove_indices, col_idx] = np.nan\n",
    "\n",
    "            # Calculate the missing rate for this column\n",
    "            missing_rate = np.mean(np.isnan(data_mnar[:, col_idx])) * 100\n",
    "            missing_rates[col_idx] = missing_rate\n",
    "            #print(\"ordinal\" ,missing_rate)\n",
    "\n",
    "        elif \"nominal\" in col_type:\n",
    "            # Nominal data: Randomly choose one category and make a portion of the data missing\n",
    "            unique_vals = list(set(data_mnar[:, col_idx]))\n",
    "            chosen_val = random.choice(unique_vals)\n",
    "\n",
    "            # Get indices of the chosen category\n",
    "            chosen_indices = np.where(data_mnar[:, col_idx] == chosen_val )[0].tolist()\n",
    "\n",
    "\n",
    "            # Find the rest of the indices (those not in max_indices)\n",
    "            all_indices = set(range(data_mnar.shape[0]))\n",
    "            other_indices = list(all_indices - set(chosen_indices))\n",
    "\n",
    "            # Determine which indices to remove based on the number to remove\n",
    "            if len(chosen_indices) >= num_to_remove:\n",
    "                remove_indices = random.sample(chosen_indices, num_to_remove)\n",
    "            else:\n",
    "                # If there are not enough max_indices, take all max_indices and supplement with random others\n",
    "                remove_indices = chosen_indices\n",
    "                random_indices = random.sample(other_indices, num_to_remove - len(remove_indices))\n",
    "                remove_indices = remove_indices + random_indices\n",
    "\n",
    "\n",
    "            data_mnar[remove_indices, col_idx] = np.nan\n",
    "\n",
    "            # Calculate the missing rate for this column\n",
    "            missing_rate = np.mean(np.isnan(data_mnar[:, col_idx])) * 100\n",
    "            #print(\"nominal\",missing_rate)\n",
    "            missing_rates[col_idx] = missing_rate\n",
    "\n",
    "    return data_mnar\n",
    "\n",
    "\n",
    "for dataname in namelist:\n",
    "    data = np.array(pd.read_csv(f\"dataset/{dataname}/features.csv\"))\n",
    "    with open(f\"dataset/{dataname}/column_info.json\", 'r') as f:\n",
    "        col_info = json.load(f)\n",
    "    \n",
    "    for rate in missing_rate:\n",
    "        missingdata = make_mnar_columnwise(data, col_info, q=rate)\n",
    "\n",
    "        #missing_rates = calculate_missing_rates(missingdata)\n",
    "        \n",
    "        output_dir = f\"dataset_nan/{dataname}/mnar\"\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "\n",
    "    #Save the data with missing values as a NumPy array\n",
    "        np.save(f\"{output_dir}/{rate}.npy\", missingdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def apply_missing_rate(data, missing_rate):\n",
    "    # Flatten the data to simplify the process\n",
    "    flat_data = data.flatten()\n",
    "\n",
    "    # Count the existing missing values\n",
    "    total_elements = flat_data.size\n",
    "    current_missing_count = np.sum(np.isnan(flat_data))\n",
    "\n",
    "    # Calculate the target number of missing values\n",
    "    target_missing_count = int(missing_rate * total_elements)\n",
    "\n",
    "    # Calculate how many more values need to be removed\n",
    "    additional_missing_count = target_missing_count - current_missing_count\n",
    "\n",
    "    if additional_missing_count <= 0:\n",
    "        # If the current missing rate is already higher than or equal to the target, return the original data\n",
    "        return data\n",
    "\n",
    "    # Identify indices that are not already missing\n",
    "    available_indices = np.where(~np.isnan(flat_data))[0]\n",
    "\n",
    "    # Randomly select indices to remove additional data\n",
    "    indices_to_remove = np.random.choice(available_indices, additional_missing_count, replace=False)\n",
    "\n",
    "    # Set the selected indices to np.nan to represent missing data\n",
    "    flat_data[indices_to_remove] = np.nan\n",
    "\n",
    "    # Reshape the flat data back to the original shape\n",
    "    return flat_data.reshape(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall missing rate: 16.68%\n",
      "Overall missing rate: 49.99%\n",
      "Overall missing rate: 49.99%\n"
     ]
    }
   ],
   "source": [
    "dataname = \"heart\"\n",
    "used_rate = 0.2\n",
    "actual_rate = 0.6\n",
    "output_dir = f\"dataset_nan/{dataname}/mar\"\n",
    "used_data = np.load(f\"{output_dir}/{used_rate}.npy\")\n",
    "calculate_missing_rates(used_data)\n",
    "\n",
    "actual_data = np.load(f\"{output_dir}/{actual_rate}.npy\")\n",
    "calculate_missing_rates(actual_data)\n",
    "save = 1\n",
    "\n",
    "if save:\n",
    "    modified = apply_missing_rate(used_data, 0.50)\n",
    "\n",
    "    calculate_missing_rates(modified)\n",
    "\n",
    "    np.save(f\"{output_dir}/{actual_rate}.npy\", modified)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Missing Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Type = mcar, Data = car, Rate = 0.05\n",
      "Overall missing rate: 5.00%\n",
      "Processing: Type = mcar, Data = car, Rate = 0.1\n",
      "Overall missing rate: 9.99%\n",
      "Processing: Type = mcar, Data = car, Rate = 0.2\n",
      "Overall missing rate: 19.99%\n",
      "Processing: Type = mcar, Data = car, Rate = 0.3\n",
      "Overall missing rate: 30.00%\n",
      "Processing: Type = mcar, Data = car, Rate = 0.4\n",
      "Overall missing rate: 40.00%\n",
      "Processing: Type = mcar, Data = car, Rate = 0.5\n",
      "Overall missing rate: 50.00%\n",
      "Processing: Type = mcar, Data = car, Rate = 0.6\n",
      "Overall missing rate: 59.99%\n",
      "Processing: Type = mcar, Data = car, Rate = 0.7\n",
      "Overall missing rate: 69.99%\n",
      "Processing: Type = mcar, Data = car, Rate = 0.8\n",
      "Overall missing rate: 80.00%\n",
      "\n",
      "Processing: Type = mcar, Data = breast, Rate = 0.05\n",
      "Overall missing rate: 9.05%\n",
      "Processing: Type = mcar, Data = breast, Rate = 0.1\n",
      "Overall missing rate: 13.75%\n",
      "Processing: Type = mcar, Data = breast, Rate = 0.2\n",
      "Overall missing rate: 23.27%\n",
      "Processing: Type = mcar, Data = breast, Rate = 0.3\n",
      "Overall missing rate: 33.06%\n",
      "Processing: Type = mcar, Data = breast, Rate = 0.4\n",
      "Overall missing rate: 42.50%\n",
      "Processing: Type = mcar, Data = breast, Rate = 0.5\n",
      "Overall missing rate: 51.98%\n",
      "Processing: Type = mcar, Data = breast, Rate = 0.6\n",
      "Overall missing rate: 61.50%\n",
      "Processing: Type = mcar, Data = breast, Rate = 0.7\n",
      "Overall missing rate: 71.02%\n",
      "Processing: Type = mcar, Data = breast, Rate = 0.8\n",
      "Overall missing rate: 80.77%\n",
      "\n",
      "Processing: Type = mcar, Data = australian, Rate = 0.05\n",
      "Overall missing rate: 5.00%\n",
      "Processing: Type = mcar, Data = australian, Rate = 0.1\n",
      "Overall missing rate: 10.00%\n",
      "Processing: Type = mcar, Data = australian, Rate = 0.2\n",
      "Overall missing rate: 20.00%\n",
      "Processing: Type = mcar, Data = australian, Rate = 0.3\n",
      "Overall missing rate: 30.00%\n",
      "Processing: Type = mcar, Data = australian, Rate = 0.4\n",
      "Overall missing rate: 40.00%\n",
      "Processing: Type = mcar, Data = australian, Rate = 0.5\n",
      "Overall missing rate: 50.00%\n",
      "Processing: Type = mcar, Data = australian, Rate = 0.6\n",
      "Overall missing rate: 60.00%\n",
      "Processing: Type = mcar, Data = australian, Rate = 0.7\n",
      "Overall missing rate: 70.00%\n",
      "Processing: Type = mcar, Data = australian, Rate = 0.8\n",
      "Overall missing rate: 80.00%\n",
      "\n",
      "Processing: Type = mcar, Data = heart, Rate = 0.05\n",
      "Overall missing rate: 5.08%\n",
      "Processing: Type = mcar, Data = heart, Rate = 0.1\n",
      "Overall missing rate: 10.05%\n",
      "Processing: Type = mcar, Data = heart, Rate = 0.2\n",
      "Overall missing rate: 20.06%\n",
      "Processing: Type = mcar, Data = heart, Rate = 0.3\n",
      "Overall missing rate: 30.03%\n",
      "Processing: Type = mcar, Data = heart, Rate = 0.4\n",
      "Overall missing rate: 40.04%\n",
      "Processing: Type = mcar, Data = heart, Rate = 0.5\n",
      "Overall missing rate: 50.04%\n",
      "Processing: Type = mcar, Data = heart, Rate = 0.6\n",
      "Overall missing rate: 60.04%\n",
      "Processing: Type = mcar, Data = heart, Rate = 0.7\n",
      "Overall missing rate: 70.02%\n",
      "Processing: Type = mcar, Data = heart, Rate = 0.8\n",
      "Overall missing rate: 80.02%\n",
      "\n",
      "Processing: Type = mcar, Data = adult, Rate = 0.05\n",
      "Overall missing rate: 5.31%\n",
      "Processing: Type = mcar, Data = adult, Rate = 0.1\n",
      "Overall missing rate: 10.29%\n",
      "Processing: Type = mcar, Data = adult, Rate = 0.2\n",
      "Overall missing rate: 20.26%\n",
      "Processing: Type = mcar, Data = adult, Rate = 0.3\n",
      "Overall missing rate: 30.23%\n",
      "Processing: Type = mcar, Data = adult, Rate = 0.4\n",
      "Overall missing rate: 40.20%\n",
      "Processing: Type = mcar, Data = adult, Rate = 0.5\n",
      "Overall missing rate: 50.16%\n",
      "Processing: Type = mcar, Data = adult, Rate = 0.6\n",
      "Overall missing rate: 60.13%\n",
      "Processing: Type = mcar, Data = adult, Rate = 0.7\n",
      "Overall missing rate: 70.10%\n",
      "Processing: Type = mcar, Data = adult, Rate = 0.8\n",
      "Overall missing rate: 80.06%\n",
      "\n",
      "Processing: Type = mcar, Data = student, Rate = 0.05\n",
      "Overall missing rate: 5.00%\n",
      "Processing: Type = mcar, Data = student, Rate = 0.1\n",
      "Overall missing rate: 10.00%\n",
      "Processing: Type = mcar, Data = student, Rate = 0.2\n",
      "Overall missing rate: 20.00%\n",
      "Processing: Type = mcar, Data = student, Rate = 0.3\n",
      "Overall missing rate: 30.00%\n",
      "Processing: Type = mcar, Data = student, Rate = 0.4\n",
      "Overall missing rate: 40.00%\n",
      "Processing: Type = mcar, Data = student, Rate = 0.5\n",
      "Overall missing rate: 50.00%\n",
      "Processing: Type = mcar, Data = student, Rate = 0.6\n",
      "Overall missing rate: 60.00%\n",
      "Processing: Type = mcar, Data = student, Rate = 0.7\n",
      "Overall missing rate: 70.00%\n",
      "Processing: Type = mcar, Data = student, Rate = 0.8\n",
      "Overall missing rate: 80.00%\n",
      "\n",
      "Processing: Type = mcar, Data = banknote, Rate = 0.05\n",
      "Overall missing rate: 4.99%\n",
      "Processing: Type = mcar, Data = banknote, Rate = 0.1\n",
      "Overall missing rate: 9.99%\n",
      "Processing: Type = mcar, Data = banknote, Rate = 0.2\n",
      "Overall missing rate: 19.99%\n",
      "Processing: Type = mcar, Data = banknote, Rate = 0.3\n",
      "Overall missing rate: 29.99%\n",
      "Processing: Type = mcar, Data = banknote, Rate = 0.4\n",
      "Overall missing rate: 40.00%\n",
      "Processing: Type = mcar, Data = banknote, Rate = 0.5\n",
      "Overall missing rate: 50.00%\n",
      "Processing: Type = mcar, Data = banknote, Rate = 0.6\n",
      "Overall missing rate: 59.99%\n",
      "Processing: Type = mcar, Data = banknote, Rate = 0.7\n",
      "Overall missing rate: 69.99%\n",
      "Processing: Type = mcar, Data = banknote, Rate = 0.8\n",
      "Overall missing rate: 79.99%\n",
      "\n",
      "Processing: Type = mcar, Data = sonar, Rate = 0.05\n",
      "Overall missing rate: 5.00%\n",
      "Processing: Type = mcar, Data = sonar, Rate = 0.1\n",
      "Overall missing rate: 10.00%\n",
      "Processing: Type = mcar, Data = sonar, Rate = 0.2\n",
      "Overall missing rate: 20.00%\n",
      "Processing: Type = mcar, Data = sonar, Rate = 0.3\n",
      "Overall missing rate: 30.00%\n",
      "Processing: Type = mcar, Data = sonar, Rate = 0.4\n",
      "Overall missing rate: 40.00%\n",
      "Processing: Type = mcar, Data = sonar, Rate = 0.5\n",
      "Overall missing rate: 50.00%\n",
      "Processing: Type = mcar, Data = sonar, Rate = 0.6\n",
      "Overall missing rate: 60.00%\n",
      "Processing: Type = mcar, Data = sonar, Rate = 0.7\n",
      "Overall missing rate: 70.00%\n",
      "Processing: Type = mcar, Data = sonar, Rate = 0.8\n",
      "Overall missing rate: 80.00%\n",
      "\n",
      "Processing: Type = mcar, Data = spam, Rate = 0.05\n",
      "Overall missing rate: 5.00%\n",
      "Processing: Type = mcar, Data = spam, Rate = 0.1\n",
      "Overall missing rate: 10.00%\n",
      "Processing: Type = mcar, Data = spam, Rate = 0.2\n",
      "Overall missing rate: 20.00%\n",
      "Processing: Type = mcar, Data = spam, Rate = 0.3\n",
      "Overall missing rate: 30.00%\n",
      "Processing: Type = mcar, Data = spam, Rate = 0.4\n",
      "Overall missing rate: 40.00%\n",
      "Processing: Type = mcar, Data = spam, Rate = 0.5\n",
      "Overall missing rate: 50.00%\n",
      "Processing: Type = mcar, Data = spam, Rate = 0.6\n",
      "Overall missing rate: 60.00%\n",
      "Processing: Type = mcar, Data = spam, Rate = 0.7\n",
      "Overall missing rate: 70.00%\n",
      "Processing: Type = mcar, Data = spam, Rate = 0.8\n",
      "Overall missing rate: 80.00%\n",
      "\n",
      "Processing: Type = mcar, Data = wine, Rate = 0.05\n",
      "Overall missing rate: 5.00%\n",
      "Processing: Type = mcar, Data = wine, Rate = 0.1\n",
      "Overall missing rate: 10.00%\n",
      "Processing: Type = mcar, Data = wine, Rate = 0.2\n",
      "Overall missing rate: 20.00%\n",
      "Processing: Type = mcar, Data = wine, Rate = 0.3\n",
      "Overall missing rate: 30.00%\n",
      "Processing: Type = mcar, Data = wine, Rate = 0.4\n",
      "Overall missing rate: 40.00%\n",
      "Processing: Type = mcar, Data = wine, Rate = 0.5\n",
      "Overall missing rate: 50.00%\n",
      "Processing: Type = mcar, Data = wine, Rate = 0.6\n",
      "Overall missing rate: 60.00%\n",
      "Processing: Type = mcar, Data = wine, Rate = 0.7\n",
      "Overall missing rate: 70.00%\n",
      "Processing: Type = mcar, Data = wine, Rate = 0.8\n",
      "Overall missing rate: 80.00%\n",
      "\n",
      "Processing: Type = mar, Data = car, Rate = 0.05\n",
      "Overall missing rate: 4.07%\n",
      "Processing: Type = mar, Data = car, Rate = 0.1\n",
      "Overall missing rate: 8.02%\n",
      "Processing: Type = mar, Data = car, Rate = 0.2\n",
      "Overall missing rate: 16.91%\n",
      "Processing: Type = mar, Data = car, Rate = 0.3\n",
      "Overall missing rate: 24.99%\n",
      "Processing: Type = mar, Data = car, Rate = 0.4\n",
      "Overall missing rate: 33.39%\n",
      "Processing: Type = mar, Data = car, Rate = 0.5\n",
      "Overall missing rate: 41.55%\n",
      "Processing: Type = mar, Data = car, Rate = 0.6\n",
      "Overall missing rate: 50.26%\n",
      "Processing: Type = mar, Data = car, Rate = 0.7\n",
      "Overall missing rate: 58.89%\n",
      "Processing: Type = mar, Data = car, Rate = 0.8\n",
      "Overall missing rate: 66.72%\n",
      "\n",
      "Processing: Type = mar, Data = breast, Rate = 0.05\n",
      "Overall missing rate: 4.16%\n",
      "Processing: Type = mar, Data = breast, Rate = 0.1\n",
      "Overall missing rate: 12.16%\n",
      "Processing: Type = mar, Data = breast, Rate = 0.2\n",
      "Overall missing rate: 19.97%\n",
      "Processing: Type = mar, Data = breast, Rate = 0.3\n",
      "Overall missing rate: 30.57%\n",
      "Processing: Type = mar, Data = breast, Rate = 0.4\n",
      "Overall missing rate: 39.98%\n",
      "Processing: Type = mar, Data = breast, Rate = 0.5\n",
      "Overall missing rate: 46.62%\n",
      "Processing: Type = mar, Data = breast, Rate = 0.6\n",
      "Overall missing rate: 54.97%\n",
      "Processing: Type = mar, Data = breast, Rate = 0.7\n",
      "Overall missing rate: 65.00%\n",
      "Processing: Type = mar, Data = breast, Rate = 0.8\n",
      "Overall missing rate: 72.61%\n",
      "\n",
      "Processing: Type = mar, Data = australian, Rate = 0.05\n",
      "Overall missing rate: 4.29%\n",
      "Processing: Type = mar, Data = australian, Rate = 0.1\n",
      "Overall missing rate: 8.67%\n",
      "Processing: Type = mar, Data = australian, Rate = 0.2\n",
      "Overall missing rate: 16.94%\n",
      "Processing: Type = mar, Data = australian, Rate = 0.3\n",
      "Overall missing rate: 25.46%\n",
      "Processing: Type = mar, Data = australian, Rate = 0.4\n",
      "Overall missing rate: 34.76%\n",
      "Processing: Type = mar, Data = australian, Rate = 0.5\n",
      "Overall missing rate: 42.98%\n",
      "Processing: Type = mar, Data = australian, Rate = 0.6\n",
      "Overall missing rate: 51.81%\n",
      "Processing: Type = mar, Data = australian, Rate = 0.7\n",
      "Overall missing rate: 59.59%\n",
      "Processing: Type = mar, Data = australian, Rate = 0.8\n",
      "Overall missing rate: 69.20%\n",
      "\n",
      "Processing: Type = mar, Data = heart, Rate = 0.05\n",
      "Overall missing rate: 4.32%\n",
      "Processing: Type = mar, Data = heart, Rate = 0.1\n",
      "Overall missing rate: 7.95%\n",
      "Processing: Type = mar, Data = heart, Rate = 0.2\n",
      "Overall missing rate: 16.68%\n",
      "Processing: Type = mar, Data = heart, Rate = 0.3\n",
      "Overall missing rate: 24.98%\n",
      "Processing: Type = mar, Data = heart, Rate = 0.4\n",
      "Overall missing rate: 32.98%\n",
      "Processing: Type = mar, Data = heart, Rate = 0.5\n",
      "Overall missing rate: 41.99%\n",
      "Processing: Type = mar, Data = heart, Rate = 0.6\n",
      "Overall missing rate: 49.99%\n",
      "Processing: Type = mar, Data = heart, Rate = 0.7\n",
      "Overall missing rate: 59.10%\n",
      "Processing: Type = mar, Data = heart, Rate = 0.8\n",
      "Overall missing rate: 67.91%\n",
      "\n",
      "Processing: Type = mar, Data = adult, Rate = 0.05\n",
      "Overall missing rate: 4.00%\n",
      "Processing: Type = mar, Data = adult, Rate = 0.1\n",
      "Overall missing rate: 8.91%\n",
      "Processing: Type = mar, Data = adult, Rate = 0.2\n",
      "Overall missing rate: 17.41%\n",
      "Processing: Type = mar, Data = adult, Rate = 0.3\n",
      "Overall missing rate: 25.89%\n",
      "Processing: Type = mar, Data = adult, Rate = 0.4\n",
      "Overall missing rate: 34.51%\n",
      "Processing: Type = mar, Data = adult, Rate = 0.5\n",
      "Overall missing rate: 43.12%\n",
      "Processing: Type = mar, Data = adult, Rate = 0.6\n",
      "Overall missing rate: 50.00%\n",
      "Processing: Type = mar, Data = adult, Rate = 0.7\n",
      "Overall missing rate: 60.07%\n",
      "Processing: Type = mar, Data = adult, Rate = 0.8\n",
      "Overall missing rate: 70.00%\n",
      "\n",
      "Processing: Type = mar, Data = student, Rate = 0.05\n",
      "Overall missing rate: 4.24%\n",
      "Processing: Type = mar, Data = student, Rate = 0.1\n",
      "Overall missing rate: 8.06%\n",
      "Processing: Type = mar, Data = student, Rate = 0.2\n",
      "Overall missing rate: 16.20%\n",
      "Processing: Type = mar, Data = student, Rate = 0.3\n",
      "Overall missing rate: 24.52%\n",
      "Processing: Type = mar, Data = student, Rate = 0.4\n",
      "Overall missing rate: 32.39%\n",
      "Processing: Type = mar, Data = student, Rate = 0.5\n",
      "Overall missing rate: 39.98%\n",
      "Processing: Type = mar, Data = student, Rate = 0.6\n",
      "Overall missing rate: 47.52%\n",
      "Processing: Type = mar, Data = student, Rate = 0.7\n",
      "Overall missing rate: 55.73%\n",
      "Processing: Type = mar, Data = student, Rate = 0.8\n",
      "Overall missing rate: 63.73%\n",
      "\n",
      "Processing: Type = mar, Data = banknote, Rate = 0.05\n",
      "Overall missing rate: 3.59%\n",
      "Processing: Type = mar, Data = banknote, Rate = 0.1\n",
      "Overall missing rate: 7.51%\n",
      "Processing: Type = mar, Data = banknote, Rate = 0.2\n",
      "Overall missing rate: 15.82%\n",
      "Processing: Type = mar, Data = banknote, Rate = 0.3\n",
      "Overall missing rate: 23.71%\n",
      "Processing: Type = mar, Data = banknote, Rate = 0.4\n",
      "Overall missing rate: 30.94%\n",
      "Processing: Type = mar, Data = banknote, Rate = 0.5\n",
      "Overall missing rate: 36.68%\n",
      "Processing: Type = mar, Data = banknote, Rate = 0.6\n",
      "Overall missing rate: 44.92%\n",
      "Processing: Type = mar, Data = banknote, Rate = 0.7\n",
      "Overall missing rate: 53.26%\n",
      "Processing: Type = mar, Data = banknote, Rate = 0.8\n",
      "Overall missing rate: 59.93%\n",
      "\n",
      "Processing: Type = mar, Data = sonar, Rate = 0.05\n",
      "Overall missing rate: 3.97%\n",
      "Processing: Type = mar, Data = sonar, Rate = 0.1\n",
      "Overall missing rate: 7.71%\n",
      "Processing: Type = mar, Data = sonar, Rate = 0.2\n",
      "Overall missing rate: 15.70%\n",
      "Processing: Type = mar, Data = sonar, Rate = 0.3\n",
      "Overall missing rate: 23.69%\n",
      "Processing: Type = mar, Data = sonar, Rate = 0.4\n",
      "Overall missing rate: 31.66%\n",
      "Processing: Type = mar, Data = sonar, Rate = 0.5\n",
      "Overall missing rate: 39.82%\n",
      "Processing: Type = mar, Data = sonar, Rate = 0.6\n",
      "Overall missing rate: 48.24%\n",
      "Processing: Type = mar, Data = sonar, Rate = 0.7\n",
      "Overall missing rate: 56.49%\n",
      "Processing: Type = mar, Data = sonar, Rate = 0.8\n",
      "Overall missing rate: 64.47%\n",
      "\n",
      "Processing: Type = mar, Data = spam, Rate = 0.05\n",
      "Overall missing rate: 4.06%\n",
      "Processing: Type = mar, Data = spam, Rate = 0.1\n",
      "Overall missing rate: 8.06%\n",
      "Processing: Type = mar, Data = spam, Rate = 0.2\n",
      "Overall missing rate: 16.12%\n",
      "Processing: Type = mar, Data = spam, Rate = 0.3\n",
      "Overall missing rate: 24.34%\n",
      "Processing: Type = mar, Data = spam, Rate = 0.4\n",
      "Overall missing rate: 32.28%\n",
      "Processing: Type = mar, Data = spam, Rate = 0.5\n",
      "Overall missing rate: 40.36%\n",
      "Processing: Type = mar, Data = spam, Rate = 0.6\n",
      "Overall missing rate: 48.57%\n",
      "Processing: Type = mar, Data = spam, Rate = 0.7\n",
      "Overall missing rate: 56.41%\n",
      "Processing: Type = mar, Data = spam, Rate = 0.8\n",
      "Overall missing rate: 64.49%\n",
      "\n",
      "Processing: Type = mar, Data = wine, Rate = 0.05\n",
      "Overall missing rate: 4.18%\n",
      "Processing: Type = mar, Data = wine, Rate = 0.1\n",
      "Overall missing rate: 8.31%\n",
      "Processing: Type = mar, Data = wine, Rate = 0.2\n",
      "Overall missing rate: 16.67%\n",
      "Processing: Type = mar, Data = wine, Rate = 0.3\n",
      "Overall missing rate: 25.07%\n",
      "Processing: Type = mar, Data = wine, Rate = 0.4\n",
      "Overall missing rate: 33.16%\n",
      "Processing: Type = mar, Data = wine, Rate = 0.5\n",
      "Overall missing rate: 41.47%\n",
      "Processing: Type = mar, Data = wine, Rate = 0.6\n",
      "Overall missing rate: 50.03%\n",
      "Processing: Type = mar, Data = wine, Rate = 0.7\n",
      "Overall missing rate: 58.24%\n",
      "Processing: Type = mar, Data = wine, Rate = 0.8\n",
      "Overall missing rate: 66.63%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "missing_type = [\"mcar\", \"mar\"]\n",
    "namelist = [\"car\", \"breast\", \"australian\", \"heart\", \"adult\", \"student\", \n",
    "            \"banknote\", \"sonar\", \"spam\", \"wine\"]\n",
    "missing_rate = [0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "\n",
    "for mtype in missing_type:\n",
    "    for dataname in namelist:\n",
    "        for rate in missing_rate:\n",
    "            output_dir = f\"dataset_nan/{dataname}/{mtype}\"\n",
    "            used_data = np.load(f\"{output_dir}/{rate}.npy\")\n",
    "            \n",
    "            print(f\"Processing: Type = {mtype}, Data = {dataname}, Rate = {rate}\")\n",
    "            calculate_missing_rates(used_data)\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
