{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\n\\nCar evaluation\\nBreast cancer\\nAustralian\\nHeart\\nAdult\\nStudent Performance\\nbanknote\\nsonar\\nSPAM\\nWINE\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"\"\n",
    "\n",
    "Car evaluation\n",
    "Breast cancer\n",
    "Australian\n",
    "Heart\n",
    "Adult\n",
    "Student Performance\n",
    "banknote\n",
    "sonar\n",
    "SPAM\n",
    "WINE\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/adult Save CSV\n",
      "dataset/adult\n",
      "Files saved successfully\n"
     ]
    }
   ],
   "source": [
    "namelist = [\"car\",\"breast\",\n",
    "            \"australian\",\"heart\",\"adult\",\"student\",\n",
    "            \"banknote\",\"sonar\",\"spam\",\"wine\"]\n",
    "namelist = [\"adult\"]\n",
    "for dataname in namelist:\n",
    "    \n",
    "    datapath = f'dataset/{dataname}'\n",
    "    os.makedirs(datapath, exist_ok=True)\n",
    "\n",
    "    load_data(dataname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wine\n",
    "def load_data(dataname):\n",
    "    if dataname == \"wine\":\n",
    "        data = fetch_ucirepo(id=186) \n",
    "        # Split the data into features and label\n",
    "        shuffled_df = data.data.original.sample(frac=1).reset_index(drop=True)\n",
    "        features = shuffled_df.iloc[:, :-1]\n",
    "        label = shuffled_df.iloc[:, -1]\n",
    "        label_encoder = LabelEncoder()\n",
    "        label = label_encoder.fit_transform(label)\n",
    "\n",
    "    elif dataname == \"spam\":\n",
    "        data = fetch_ucirepo(id=94) \n",
    "        shuffled_df = data.data.original.sample(frac=1).reset_index(drop=True)\n",
    "        features = shuffled_df.iloc[:, :-1]\n",
    "        label = shuffled_df.iloc[:, -1]\n",
    "    \n",
    "    elif dataname == \"sonar\":\n",
    "        data = fetch_ucirepo(id=151) \n",
    "        shuffled_df = data.data.original.sample(frac=1).reset_index(drop=True)\n",
    "        features = shuffled_df.iloc[:, :-1]\n",
    "        label = shuffled_df.iloc[:, -1]\n",
    "        label_encoder = LabelEncoder()\n",
    "        label = label_encoder.fit_transform(label)\n",
    "\n",
    "    elif dataname == \"banknote\":\n",
    "        data = fetch_ucirepo(id=267) \n",
    "        shuffled_df = data.data.original.sample(frac=1).reset_index(drop=True)\n",
    "        features = shuffled_df.iloc[:, :-1]\n",
    "        label = shuffled_df.iloc[:, -1]\n",
    "\n",
    "    elif dataname == \"australian\":\n",
    "        data = fetch_ucirepo(id=143)\n",
    "        shuffled_df = data.data.original.sample(frac=1).reset_index(drop=True)\n",
    "        features = shuffled_df.iloc[:, :-1]\n",
    "        label = shuffled_df.iloc[:, -1]\n",
    "\n",
    "        \n",
    "    elif dataname == \"heart\":\n",
    "        data = fetch_ucirepo(id=45)\n",
    "        shuffled_df = data.data.original.sample(frac=1).reset_index(drop=True)\n",
    "        features = shuffled_df.iloc[:, :-1]\n",
    "        label = shuffled_df.iloc[:, -1]\n",
    "\n",
    "\n",
    "    elif dataname == \"adult\":\n",
    "        data = fetch_ucirepo(id=2)\n",
    "        shuffled_df = data.data.original.sample(frac=1).reset_index(drop=True)\n",
    "        features = shuffled_df.iloc[:, :-1]\n",
    "        label = shuffled_df.iloc[:, -1]\n",
    "        label_encoder = LabelEncoder()\n",
    "        label = label_encoder.fit_transform(label)\n",
    "\n",
    "\n",
    "    elif dataname == \"student\":\n",
    "        data = fetch_ucirepo(id=320)\n",
    "        shuffled_df = data.data.original.sample(frac=1).reset_index(drop=True)\n",
    "        shuffled_df['G3_category'] = pd.cut(shuffled_df['G3'], bins=5,labels=[0, 1, 2, 3, 4,])\n",
    "        features = shuffled_df.iloc[:, :-4]\n",
    "        label = shuffled_df['G3_category'] \n",
    "        \n",
    "    elif dataname == \"car\":\n",
    "        data = fetch_ucirepo(id=19)\n",
    "        shuffled_df = data.data.original.sample(frac=1).reset_index(drop=True)\n",
    "        features = shuffled_df.iloc[:, :-1]\n",
    "        label = shuffled_df.iloc[:, -1]\n",
    "        label_encoder = LabelEncoder()\n",
    "        label = label_encoder.fit_transform(label)\n",
    "\n",
    "    elif dataname == \"breast\":\n",
    "        data = fetch_ucirepo(id=14)\n",
    "        shuffled_df = data.data.original.sample(frac=1).reset_index(drop=True)\n",
    "        features = shuffled_df.iloc[:, :-1]\n",
    "        label = shuffled_df.iloc[:, -1]\n",
    "        label_encoder = LabelEncoder()\n",
    "        label = label_encoder.fit_transform(label)\n",
    "        \n",
    "    save_data(features,label,datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(features,label,datapath):\n",
    "\n",
    "    pd.DataFrame(features).to_csv(f'{datapath}/features.csv', index=False)\n",
    "    pd.DataFrame(label).to_csv(f'{datapath}/label.csv', index=False)\n",
    "\n",
    "    print(f\"{datapath} Save CSV\")\n",
    "    # Convert to NumPy arrays\n",
    "    features_np = features\n",
    "    label_np = label\n",
    "\n",
    "\n",
    "    try:\n",
    "        print(datapath)\n",
    "        np.save(f'{datapath}/features.npy', features_np)\n",
    "        np.save(f'{datapath}/label.npy', label_np)\n",
    "        print(\"Files saved successfully\")\n",
    "    except Exception as e:\n",
    "        print(\"Fail to save npy\")\n",
    "        print(f\"Error: {e}\")\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## deal with missing, Need to delete later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contains NaN: True\n",
      "Total number of NaN values: 2203\n",
      "Number of NaN values in each column: [  0 963   0   0   0   0 966   0   0   0   0   0   0 274]\n",
      "Data saved\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "namelist = [\"breast\", \"heart\", \"adult\"]\n",
    "namelist = [\"adult\"]\n",
    "def count_and_replace_nans(data):\n",
    "    has_nan = False\n",
    "    total_nan_count = 0\n",
    "    column_nan_counts = np.zeros(data.shape[1], dtype=int)\n",
    "    \n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            try:\n",
    "                if np.isnan(data[i, j]):\n",
    "                    has_nan = True\n",
    "                    total_nan_count += 1\n",
    "                    column_nan_counts[j] += 1\n",
    "                    # Check if column is categorical (string type)\n",
    "                    if isinstance(data[0, j], str) or isinstance(data[1, j], str):\n",
    "                        data[i, j] = 'Na'\n",
    "                    else:\n",
    "                        data[i, j] = 0  # Replace numerical NaN with 0\n",
    "            except TypeError:\n",
    "                continue\n",
    "    return has_nan, total_nan_count, column_nan_counts, data\n",
    "\n",
    "for dataname in namelist:\n",
    "    datapath = f'dataset/{dataname}'\n",
    "    data = np.load(f'{datapath}/features.npy', allow_pickle=True)\n",
    "    data1 = pd.read_csv(f'{datapath}/features.csv')\n",
    "\n",
    "\n",
    "    # Check if there are any NaN values and count them, replace as needed\n",
    "    has_nan, total_nan_count, column_nan_counts, updated_data = count_and_replace_nans(data)\n",
    "    \n",
    "    print(f\"Contains NaN: {has_nan}\")\n",
    "    print(f\"Total number of NaN values: {total_nan_count}\")\n",
    "    print(f\"Number of NaN values in each column: {column_nan_counts}\")\n",
    "\n",
    "    # Save the updated data back to .npy file\n",
    "    np.save(f'{datapath}/features.npy', updated_data)\n",
    "\n",
    "    print('Data saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\"car\",\"breast\",\n",
    "            \"australian\",\"heart\",\"adult\",\"student\",\n",
    "            \"banknote\",\"sonar\",\"spam\",\"wine\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Column Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "namelist = [\"banknote\",\"sonar\",\"spam\",\"wine\"]\n",
    "for dataname in namelist:\n",
    "    info = {}\n",
    "    datapath = f'dataset/{dataname}'\n",
    "    data1 = pd.read_csv(f'{datapath}/features.csv')\n",
    "    for i,j in enumerate(data1.columns):\n",
    "     info[i] = \"numerical\"\n",
    "\n",
    "         # Save the info dictionary to a JSON file\n",
    "    json_path = f'{datapath}/column_info.json'\n",
    "    with open(json_path, 'w') as json_file:\n",
    "        json.dump(info, json_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column information for adult saved to dataset/adult/column_info.json\n",
      "Converted data for adult saved to dataset/adult/features.csv\n"
     ]
    }
   ],
   "source": [
    "car_mapping = {\n",
    "            \"buying\": {\"vhigh\": 4, \"high\": 3, \"med\": 2, \"low\": 1},\n",
    "            \"maint\": {\"vhigh\": 4, \"high\": 3, \"med\": 2, \"low\": 1},\n",
    "            \"doors\": {\"2\": 2, \"3\": 3, \"4\": 4, \"5more\": 5},\n",
    "            \"persons\": {\"2\": 2, \"4\": 4, \"more\": 5},\n",
    "            \"lug_boot\": {\"small\": 1, \"med\": 2, \"big\": 3},\n",
    "            \"safety\": {\"low\": 1, \"med\": 2, \"high\": 3}\n",
    "        }\n",
    "breast_mapping = {\n",
    "    \"age\": {'50-59': 3, '40-49': 2, '60-69': 4, '30-39': 1, '70-79': 5, '20-29': 0},\n",
    "    \"menopause\": {'premeno': 0, 'ge40': 1, 'lt40': 2},\n",
    "    \"tumor-size\": {'30-34': 6, '25-29': 5, '20-24': 4, '15-19': 3, '10-14': 2, '40-44': 8, '35-39': 7, '50-54': 10, '0-4': 0, '5-9': 1, '45-49': 9},\n",
    "    \"inv-nodes\": {'0-2': 0, '3-5': 1, '6-8': 2, '9-11': 3, '12-14': 4, '15-17': 5, '24-26': 6},\n",
    "    \"node-caps\": {'no': 0, 'yes': 1},\n",
    "    \"deg-malig\": {2: 0, 3: 1, 1: 2},\n",
    "    \"breast\": {'left': 0, 'right': 1},\n",
    "    \"breast-quad\": {'left_low': 0, 'left_up': 1, 'right_up': 2, 'right_low': 3, 'central': 4},\n",
    "    \"irradiat\": {'no': 0, 'yes': 1}\n",
    "}\n",
    "australian_mapping = {\n",
    "    \"A1\":{0:0,1:1},\n",
    "    \"A4\":{1:0, 2:1, 3:2},\n",
    "    \"A5\":{1:0,2:1,3:2,4:3,5:4,6:5,7:6,8:7,9:8,10:9,11:10,12:11,13:12,14:13},\n",
    "    \"A6\":{1:0,2:1,3:2,4:3,5:4,6:5,7:6,8:7,9:8},\n",
    "    \"A8\":{0:0,1:1},\n",
    "    \"A9\":{0:0,1:1},\n",
    "    \"A11\":{0:0,1:1},\n",
    "    \"A12\":{1:0, 2:1, 3:2 }\n",
    "}\n",
    "\n",
    "heart_mapping = {\n",
    "\"sex\":{1: 1, 0: 0},\n",
    "\"cp\":{4: 4, 3: 3, 2: 2, 1: 1},\n",
    "\"fbs\":{0: 0, 1: 1},\n",
    "\"restecg\":{0: 0, 2: 2, 1: 1},\n",
    "\"exang\":{0: 0, 1: 1},\n",
    "\"slope\":{1: 1, 2: 2, 3: 3},\n",
    "\"ca\":{0.0: 0, 1.0: 1, 2.0: 2, 3.0: 3},\n",
    "\"thal\":{3.0: 3, 7.0: 7, 6.0: 6},       \n",
    "}\n",
    "\n",
    "adult_mapping = {\n",
    "   #nominal\n",
    "\"workclass\": {'Private': 1, 'Self-emp-not-inc': 2, 'Local-gov': 3, 'State-gov': 4, '?': 5, 'Self-emp-inc': 6, 'Federal-gov': 7, 'Without-pay': 8, 'Never-worked': 0},\n",
    "# ordinal\n",
    "\"education\": {\"Preschool\": 0,\n",
    "              \"1st-4th\": 1,\n",
    "              \"5th-6th\": 2,\n",
    "               \"7th-8th\": 3,\n",
    "               \"9th\": 4,\n",
    "               \"10th\": 5,\n",
    "               \"11th\": 6,\n",
    "               \"12th\": 7,\n",
    "               \"HS-grad\": 8,\n",
    "               \"Some-college\": 9,\n",
    "               \"Assoc-voc\": 10,\n",
    "               \"Assoc-acdm\": 11,\n",
    "               \"Bachelors\": 12,\n",
    "               \"Masters\": 13,\n",
    "               \"Prof-school\": 14,\n",
    "               \"Doctorate\": 15},\n",
    "# nominal\n",
    "\"marital-status\": {'Married-civ-spouse': 1,\n",
    "                   'Never-married': 2,\n",
    "                   'Divorced': 3,\n",
    "                   'Separated': 4,\n",
    "                   'Widowed': 5,\n",
    "                   'Married-spouse-absent': 6,\n",
    "                   'Married-AF-spouse': 0},\n",
    "# nominal\n",
    "\"occupation\": {'Prof-specialty': 1, \n",
    "               'Craft-repair': 2, \n",
    "               'Exec-managerial': 3, \n",
    "               'Adm-clerical': 4, \n",
    "               'Sales': 5, \n",
    "               'Other-service': 6, \n",
    "               'Machine-op-inspct': 7, \n",
    "               'Transport-moving': 8, \n",
    "               'Handlers-cleaners': 9, \n",
    "               '?': 10, \n",
    "               'Farming-fishing': 11, \n",
    "               'Tech-support': 12, \n",
    "               'Protective-serv': 13, \n",
    "               'Priv-house-serv': 14, \n",
    "               'Armed-Forces': 0},\n",
    "# nominal\n",
    "\"relationship\": {'Husband': 1,\n",
    "                  'Not-in-family': 2,\n",
    "                  'Own-child': 3,\n",
    "                  'Unmarried': 4, \n",
    "                  'Wife': 5, \n",
    "                  'Other-relative': 0},\n",
    "# nominal\n",
    "\"race\": {'White': 1, 'Black': 2, \n",
    "         'Asian-Pac-Islander': 3, 'Amer-Indian-Eskimo': 4, \n",
    "         'Other': 0},\n",
    "# nominal\n",
    "\"sex\": {\"Female\":0, \n",
    "        \"Male\" : 1},\n",
    "# nominal\n",
    "\"native-country\": {'United-States': 1, 'Mexico': 2, '?': 3, 'Philippines': 4, 'Germany': 5, \n",
    "                   'Puerto-Rico': 6, 'Canada': 7, 'El-Salvador': 8, 'India': 9, 'Cuba': 10, \n",
    "                   'England': 11, 'China': 12, 'South': 13, 'Jamaica': 14, 'Italy': 15, \n",
    "                   'Dominican-Republic': 16, 'Japan': 17, 'Guatemala': 18, 'Poland': 19, 'Vietnam': 20, \n",
    "                   'Columbia': 21, 'Haiti': 22, 'Portugal': 23, 'Taiwan': 24, 'Iran': 25, 'Nicaragua': 26,\n",
    "                     'Greece': 27, 'Peru': 28, 'Ecuador': 29, 'France': 30, 'Ireland': 31, 'Hong': 32, \n",
    "                     'Thailand': 33, 'Cambodia': 34, 'Trinadad&Tobago': 35, 'Outlying-US(Guam-USVI-etc)': 36, \n",
    "                     'Laos': 37, 'Yugoslavia': 38, 'Scotland': 39, 'Honduras': 40, 'Hungary': 41, 'Holand-Netherlands': 0}\n",
    "}\n",
    "\n",
    "student_mapping = {\n",
    "   \"school\": {'GP': 0, 'MS': 1},\n",
    "   \"sex\":{'F': 0, 'M': 1},\n",
    "   \"address\": {'U': 0, 'R': 1},\n",
    "   \"famsize\":{'GT3': 0, 'LE3': 1},\n",
    "   \"Pstatus\":{'T': 0, 'A': 1},\n",
    "   \"Medu\": {2: 2, 4: 4, 1: 1, 3: 3, 0: 0}, # ordinal\n",
    "   \"Fedu\": {2: 2, 1: 1, 3: 3, 4: 4, 0: 0},# ordinal\n",
    "   \"Mjob\":{'other': 4, 'services': 0, 'at_home': 1, 'teacher': 2, 'health': 3},\n",
    "   \"Fjob\":{'other': 4, 'services': 0, 'at_home': 1, 'teacher': 2, 'health': 3},\n",
    "   \"reason\":   {'course': 0, 'home': 1, 'reputation': 2, 'other': 3},\n",
    "   \"guardian\":{'mother': 0, 'father': 1, 'other': 2},\n",
    "   \"traveltime\": {1: 0, 2: 1, 3: 2, 4: 3},# ordinal\n",
    "   \"studytime\":{2: 1, 1: 0, 3: 2, 4: 3},# ordinal\n",
    "   \"failures\":{0: 0, 1: 1, 2: 2, 3: 3},# ordinal\n",
    "   \"schoolsup\":{'no': 0, 'yes': 1},\n",
    "   \"famsup\":{'no': 0, 'yes': 1},\n",
    "   \"paid\":{'no': 0, 'yes': 1},\n",
    "   \"activities\":{'no': 0, 'yes': 1},\n",
    "   \"nursery\":{'no': 0, 'yes': 1},\n",
    "   \"higher\":{'no': 0, 'yes': 1},\n",
    "   \"internet\":{'no': 0, 'yes': 1},\n",
    "   \"romantic\":{'no': 0, 'yes': 1},\n",
    "   \"famrel\":{4: 3, 5: 4, 3: 2, 2: 1, 1: 0},# ordinal\n",
    "   \"freetime\":{4: 3, 5: 4, 3: 2, 2: 1, 1: 0},# ordinal\n",
    "   \"goout\":{4: 3, 5: 4, 3: 2, 2: 1, 1: 0},# ordinal\n",
    "   \"Dalc\":{4: 3, 5: 4, 3: 2, 2: 1, 1: 0},# ordinal\n",
    "   \"Walc\":{4: 3, 5: 4, 3: 2, 2: 1, 1: 0},# ordinal\n",
    "   \"health\":{4: 3, 5: 4, 3: 2, 2: 1, 1: 0},# ordinal\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "namelist = [\"car\",\"breast\",\n",
    "            \"australian\",\"heart\",\"adult\",\"student\"]\n",
    "namelist = [\"adult\"]\n",
    "\n",
    "for dataname in namelist:\n",
    "   info = {}\n",
    "   datapath = f'dataset/{dataname}'\n",
    "   data1 = pd.read_csv(f'{datapath}/features.csv')\n",
    "   if dataname == \"car\":\n",
    "      for i,j in enumerate(data1.columns):\n",
    "         info[i] = {\"ordinal\":car_mapping[j]}\n",
    "         data1[j] = data1[j].map(car_mapping[j])\n",
    "   elif dataname == \"breast\":\n",
    "      for i,j in enumerate(data1.columns):\n",
    "         if j in [\"menopause\" , \"node-caps\", \"breast\", \"breast-quad\", \"irradiat\" ]:\n",
    "            info[i] = {\"nominal\":breast_mapping[j]}\n",
    "         else:\n",
    "            info[i] = {\"ordinal\":breast_mapping[j]}\n",
    "         data1[j] = data1[j].map(breast_mapping[j])\n",
    "            \n",
    "   elif dataname == \"australian\":\n",
    "      for i,j in enumerate(data1.columns):\n",
    "         if j in australian_mapping.keys():\n",
    "            info[i] = {\"nominal\":australian_mapping[j]}\n",
    "            data1[j] = data1[j].map(australian_mapping[j])\n",
    "         else:\n",
    "            info[i] = \"numerical\"\n",
    "\n",
    "   elif dataname == \"heart\":\n",
    "      for i,j in enumerate(data1.columns):\n",
    "         if j in heart_mapping.keys():\n",
    "            info[i] = {\"ordinal\":heart_mapping[j]}\n",
    "            data1[j] = data1[j].map(heart_mapping[j])\n",
    "         else:\n",
    "            info[i] = \"numerical\"\n",
    "\n",
    "\n",
    "   elif dataname == \"adult\":\n",
    "      for i,j in enumerate(data1.columns):\n",
    "         if j in adult_mapping.keys():\n",
    "            if j == \"education\":\n",
    "               info[i] = {\"ordinal\":adult_mapping[j]}\n",
    "            else:\n",
    "               info[i] = {\"nominal\":adult_mapping[j]}\n",
    "            data1[j] = data1[j].map(adult_mapping[j])\n",
    "         else:\n",
    "            info[i] = \"numerical\"\n",
    "   elif dataname == \"student\":\n",
    "      for i,j in enumerate(data1.columns):\n",
    "         if j in student_mapping.keys():\n",
    "            if j in [ \"Medu\",\"Fedu\",\"traveltime\" ,\"studytime\",\"failures\",\"famrel\"\n",
    "                     \"freetime\",\"goout\",\"Dalc\",\"Walc\",\"health\"]:\n",
    "               info[i] = {\"ordinal\":student_mapping[j]}\n",
    "            else:\n",
    "               info[i] = {\"nominal\":student_mapping[j]}\n",
    "               data1[j] = data1[j].map(student_mapping[j])\n",
    "         else:\n",
    "            info[i] = \"numerical\"\n",
    "\n",
    "   json_path = f'{datapath}/column_info.json'\n",
    "   with open(json_path, 'w') as json_file:\n",
    "      json.dump(info, json_file, indent=4)\n",
    "    \n",
    "   print(f\"Column information for {dataname} saved to {json_path}\")\n",
    "    \n",
    "   # Save the converted data to a new CSV file\n",
    "   converted_data_path = f'{datapath}/features.csv'\n",
    "   data1.to_csv(converted_data_path, index=False)\n",
    "   print(f\"Converted data for {dataname} saved to {converted_data_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
